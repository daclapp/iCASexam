Hash MD5 on policy number and insured name for train/test/holdout split reproducibilty 
```{r}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(openssl, stringr,dplyr)

data = data.frame(pol_num = c('123-0','456-0'), insured_name = c('insured_1','insured_2'))

data = data %>% 
  mutate(hash = md5(str_c(pol_num,insured_name))) %>% 
  mutate(split = as.integer(as.hexmode(substr(hash, 1, 1)) %% 2L)) #modify 2L for different splits. what if not equal?
  #can also split by sorting on hash or cutoff values. It can actually be better to have your data reassign sample though so you would notice your models change drastically and your data may be noisier than you think. 

as.integer(as.hexmode(substr(data$hash, 1, 1))) %% 2L

data
```

Gini and Lorenz Curve

"To produce a Gini coefficient and a Lorenz curve plot for a model, it is necessary to modify the functions. Instead
of sorting based on actual data, one sorts by predicted values. It is also advisable to include a random number
column as a secondary sort key. If a model produces the same predicted value for large segments of the data, and
if those segments had been previously sorted in ascending order of actual values, and if the sort function preserves
that order, the Gini coefficient and Lorenz curve might look better than they ought to be. Introducing a random
number column as a secondary sort key avoids that issue."


re-written example from study note code 

```{r}
pacman::p_load(caTools)
set.seed(123) 

# chick_weight = as_tibble(ChickWeight) %>% 
#   mutate(count = 1) %>% #not sure this is necessary. used in weightedGini function that causes an error
#   mutate(sample = if_else(sample.split(weight, SplitRatio = .75) == T,"Train","Test")) #replace sample column above

#use same code as paper for consistent results
chick_weight = as_tibble(ChickWeight) %>% 
  mutate(count = 1) %>% 
  mutate(sample = as.factor(sample(c("Test","Train"), nrow(ChickWeight), replace=TRUE, prob = c(0.3,0.7))))
  # mutate(sample = if_else(ntile(sample(1:1000,nrow(ChickWeight),replace=T),2) ==1 , ) #this could guarentee equal weights, need to split in non-equal buckets though and map back to train test 

#check split close to target
nrow(chick_weight %>% filter(sample == "Train"))/nrow(chick_weight) 

chick_weight
```

Gini Coefficient and Lorenz Curve 
https://stackoverflow.com/questions/22679493/how-to-plot-a-nice-lorenz-curve-for-factors-in-r-ggplot
 ggplot(data=Distr1_df) +
    geom_point(aes(x=p, y=L)) +
    geom_line(aes(x=p, y=L), color="#990000") +
    scale_x_continuous(name="Cumulative share of X", limits=c(0,1)) + 
    scale_y_continuous(name="Cumulative share of Y", limits=c(0,1)) +
    geom_abline()
    
    library(ggplot2)
library(gglorenz)
    ggplot(x, aes(Distr1)) + 
  stat_lorenz() + 
  geom_abline(color = "grey")

```{r}
pacman::p_load(ineq,reldist)

train = chick_weight %>% filter(sample == "Train")

# quick output
gini(train$weight)
plot(Lc(train$weight))

#formatted output:
xtitle <- paste("Gini Coefficient =", round(gini(train$weight),5))
plot(Lc(train$weight), col = "blue", lwd = 2,
 main = "Training Sample", xlab = xtitle)
# round(with(train, WeightedGini(weight, count, weight)), 5) # email sent to CAS. no WeightedGini function


test = chick_weight %>% filter(sample == "Test")

xtitle <- paste("Gini Coefficient =", round(gini(test$weight),5))
plot(Lc(test$weight), col = "blue", lwd = 2,
 main = "Testing Sample", xlab = xtitle)

#Lc() sorts on actuals. LorenzCurve2() below sorts on predicted
```
https://www.kaggle.com/c/liberty-mutual-fire-peril/discussion/9880
http://blog.nguyenvq.com/blog/2015/09/25/calculate-the-weighted-gini-coefficient-or-auc-in-r/
```{r}
WeightedGini = function(actual,weights,predicted){
   # Modification of study note on validation for icas exam which was modified from post in Kaggle by William Cukierski
 # https://www.kaggle.com/c/liberty-mutual-fire-peril/discussion/9880
 # actual = actual frequency, severity, loss cost
 # corresponding weights = exposure, claim count, exposure
 # predicted = predicted
  set.seed(456)
  temp = data.frame(actual = actual, weights = weights, predicted = predicted)
  temp = temp %>% 
    mutate(random_key = runif(nrow(temp))) %>%  # create random number sort key so ties will be resolved in random order. if data sorted by actuals before this and didn't sort by random gini could be overstated 
    arrange(predicted,random_key) %>% 
    mutate(random = cumsum(weights/sum(weights)),
           cumPosFound = cumsum(actual*weights),
           Lorentz = cumPosFound / max(cumPosFound))
  gini = sum(temp$Lorentz[-1]*temp$random[-nrow(temp)]) - sum(temp$Lorentz[-nrow(temp)] * temp$random[-1])
  return(gini)
}
```

```{r}

# Lorenz Curve function that uses predicted values for sorting. Lc() sorts on actuals
LorenzCurve2 <- function (x, n = rep(1, length(x)), xhat, plot = FALSE)
{
 # Modification of Lc function in ineq package
 # x = actual (frequency, severity, loss cost)
 # xhat = predicted (frequency, severity, loss cost)
 # n = weights (exposure, claims, exposure)
 # data will be sorted in ascending order of prediction
 # Lorenz Curve will be plotted based on actual values
 ina <- !is.na(x)
 n <- n[ina]
 x <- as.numeric(x)[ina]
 xhat <- as.numeric(xhat)[ina]
 k <- length(x)
 # create random number sort key so ties will be resolved in random order
 #rkey <- runif(k)
 #o <- order(xhat, rkey)
 o <- order(xhat)
 x <- x[o]
 n <- n[o]
 x <- n * x
 p <- cumsum(n)/sum(n)
 L <- cumsum(x)/sum(x)
 p <- c(0, p)
 L <- c(0, L)
 L2 <- L * mean(x)/mean(n)
 Lc <- list(p, L, L2)
 names(Lc) <- c("p", "L", "L.general")
 class(Lc) <- "Lc"
 if (plot)
 plot(Lc)
 Lc
}


 
#debugonce(LorenzCurve2)
# with(train_augment, plot(LorenzCurve2(weight, count, weight_pred),
#  col="blue", lwd=2,
#  main="Training Sample", xlab=xtitle))

```

```{r}
LorenzCurve_DC <- function (data = NULL, actual = NULL, weights = NULL, predicted = NULL, plot = FALSE)
{
 # Modification of Lc function in ineq package
 # actual = x = actual (frequency, severity, loss cost)
 # weights = n = weights (exposure, claims, exposure)
 # predicted = xhat = predicted (frequency, severity, loss cost)
  
 # data will be sorted in ascending order of prediction
 # Lorenz Curve will be plotted based on actual values
  
  #add a check if actual and predicted are numeric
  
 data = data %>% 
   filter(!is.na(actual)) %>% 
   arrange_(predicted) %>% 
   mutate(totalPositive = actual * weights)
   
  
 return(data)
}

#debugonce(LorenzCurve_DC)
# LorenzCurve_DC(data = train_augment, actual = "weight", weights = "count", predicted = "weight_pred")

#  actual = "weight"
#  weights = "count"
#  predicted = "weight_pred"
# train_augment %>% 
#   filter(!is.na(actual)) %>% 
#    arrange_(predicted)
```

```{r}
round(with(train, WeightedGini(actual = weight,
                               weights = count,
                               predicted = weight)), 5)

```

```{r}
pacman::p_load(randomForest)

set.seed(456)
model_rf = randomForest(weight ~ Diet + Time, data = train)

train_augment = train %>% 
  mutate(weight_pred = predict(model_rf, train))


train_pgin = round(with(train_augment, WeightedGini(weight, count, weight_pred)), 5)


xtitle = paste("Random Forest Gini Coefficient =",
 round(train_pgin,5))

#debugonce(LorenzCurve2)
with(train_augment, plot(LorenzCurve2(weight, count, weight_pred),
 col="blue", lwd=2,
 main="Training Sample", xlab=xtitle))

# slightly different gini than the paper. train % same as source code. newer version of random forest?


# Predicted on Test Sample
test_augment = test %>% 
  mutate(weight_pred = predict(model_rf, test))

test_pgin <- round(with(test_augment,WeightedGini(weight, count, weight_pred)), 5)

xtitle <- paste("Random Forest Gini Coefficient =",
 round(test_pgin,5))

with(test_augment, plot(LorenzCurve2(weight, count, weight_pred),
 col="blue", lwd=2,
 main="Test Sample", xlab=xtitle))

norm_gini_train = round(train_pgin/gini(train$weight),5)
norm_gini_test = round(test_pgin,5)/round(gini(test$weight),5)
message('Normalized Gini on training sample = ',round(train_pgin,5),"/",round(gini(train$weight),5)," = ",norm_gini_train)
message('Normalized Gini on testing sample = ',round(test_pgin,5),"/",round(gini(test$weight),5)," = ",norm_gini_test)
message('Difference in normalized Gini = ',norm_gini_train - norm_gini_test) #or cat() but then need to insert page breaks


```


```{r}

#
# Fit linear regression training data
#

model_ols = lm(weight ~ Time,
 data = train)
# Predicted on Training Sample

train_augment = train %>% 
  mutate(weight_pred = predict(model_ols, train))

set.seed(456)
train_pgin <- round(with(train_augment,
 WeightedGini(actual = weight, weights = count, predicted = weight_pred)), 5)

xtitle <- paste("Linear Model Gini Coefficient =",
 round(train_pgin,5))

with(train_augment, plot(LorenzCurve2(weight, count, weight_pred),
 col="blue", lwd=2,
main="Training Sample", xlab=xtitle))
# Predicted on Test Sample
test_augment = test %>% 
  mutate(weight_pred = predict(model_ols, test))

test_pgin <- round(with(test_augment,
 WeightedGini(actual = weight, weights = count, predicted = weight_pred)), 5)


xtitle <- paste("Linear Model Gini Coefficient =",
 round(test_pgin,5))
with(test_augment, plot(LorenzCurve2(weight, count, weight_pred),
 col="blue", lwd=2,
 main="Test Sample", xlab=xtitle))

norm_gini_train = round(train_pgin/gini(train$weight),5)
norm_gini_test = round(test_pgin/gini(test$weight),5)
message('Normalized Gini on training sample = ',round(train_pgin,5),"/",round(gini(train$weight),5)," = ",norm_gini_train)
message('Normalized Gini on testing sample = ',round(test_pgin,5),"/",round(gini(test$weight),5)," = ",norm_gini_test)
message('Difference in normalized Gini = ',norm_gini_train - norm_gini_test) #or cat() but then need to insert page breaks

# per ?gini() weights were originally created if it's a sample and you are inputting the mean income. weights would be number of people in that group. 
```


LIFT CHARTS
to compare two or more models

car.csv info from http://www.businessandeconomics.mq.edu.au/our_departments/Applied_Finance_and_Actuarial_Studies/research/books/GLMsforInsuranceData/data_sets
This data set is based on  one-year vehicle insurance
policies taken out in 2004 or 2005. There are 67856 policies, of
which  4624 (6.8%) had at least one claim. 

Variables:

veh_value	vehicle value, in $10,000s
exposure	0-1
clm		occurrence of claim (0 = no, 1 = yes)
numclaims	number of claims
claimcst0	claim amount (0 if no claim)
veh_body	vehicle body, coded as
              BUS
              CONVT = convertible  
              COUPE   
              HBACK = hatchback                  
              HDTOP = hardtop
              MCARA = motorized caravan
              MIBUS = minibus
              PANVN = panel van
              RDSTR = roadster
              SEDAN    
              STNWG = station wagon
              TRUCK           
              UTE - utility
veh_age	age of vehicle: 1 (youngest), 2, 3, 4
gender		gender of driver: M, F
area		driver's area of residence: A, B, C, D, E, F
agecat		driver's age category: 1 (youngest), 2, 3, 4, 5, 6

```{r}
#rewriting page 13 of study note on validation
car = read.csv("data/car.csv") #from http://www.businessandeconomics.mq.edu.au/our_departments/Applied_Finance_and_Actuarial_Studies/research/books/GLMsforInsuranceData/data_sets
car = car %>% 
  rename(vehicle_value = veh_value,
         claim_ind = clm,
         claim_cost = claimcst0,
         vehicle_body = veh_body,
         vehicle_age = veh_age,
         age_cat = agecat) %>% 
  mutate(vehicle_value = vehicle_value*10000,
         vehicle_age = as.factor(vehicle_age),#why didn't they leave this as a number?
         age_cat = as.factor(age_cat)) %>% 
  select(-X_OBSTAT_) %>% 
  filter(claim_cost > 0) #since we're fitting a severity model

set.seed(189763)
car_total = car %>% 
  mutate(random = runif(nrow(car)),
         split = if_else(random < .6 ,"train","holdout")) #runif is Random number from UNIForm distribution

car_train = car_total  %>% filter(split == "train")
car_holdout = car_total %>% filter(split == "holdout")
rm(car)

```



```{r}

model_1 = glm(claim_cost ~ area + vehicle_age,
               data = car_train,
               family = Gamma(link = "log"))

model_2 = glm(claim_cost ~ area + vehicle_age + gender,
               data = car_train,
               family = Gamma(link = "log"))

model_3 = glm(claim_cost ~ area + vehicle_age + gender + age_cat + vehicle_value + vehicle_body,
               data = car_train,
               family = Gamma(link = "log"))

car_augment = car_holdout %>%
  mutate(model_1_pred = predict(model_1,newdata = car_holdout,type = "response")) %>% 
  mutate(model_2_pred = predict(model_2,newdata = car_holdout,type = "response")) %>% 
  mutate(model_3_pred = predict(model_3,newdata = car_holdout,type = "response"))

car_augment



```


```{r}
#make this a function since called twice

set.seed(13472)
car_augment_bins = car_augment %>% 
  mutate(random = runif(nrow(car_holdout))) %>% 
  arrange(model_2_pred,random) %>% 
  mutate(exposure_cumsum = cumsum(exposure)) %>% 
  arrange(model_2_pred) #not needed but to check that ntile worked


  
car_augment_bins = car_augment_bins %>% 
  mutate(bin_model_2_pred = cut(exposure_cumsum,breaks = c(0,1:9*sum(car_augment_bins$exposure)/10,sum(car_augment_bins$exposure)*1.1)))
  
#check bins worked
car_augment_bins %>% 
  group_by(bin_model_2_pred) %>% 
  summarize(total_exposure = sum(exposure),
            model_2_pred_min = min(model_2_pred),
            model_2_pred_max = max(model_2_pred),
            rows = n()) #matches line 53 tapply() exactly


car_augment_bins_graph = car_augment_bins %>% 
  group_by(bin_model_2_pred) %>% 
  summarize(model_2_pred_mean = mean(model_2_pred) / mean(car_augment_bins$model_2_pred), #replaces tapply(dt.holdout$mod.A,dt.holdout$bin.A, mean) / mean(dt.holdout$mod.A)
            actual_mean = mean(claim_cost) / mean(car_augment_bins$model_2_pred) #thought this was wrong, but CAS confirmed this is correct and matches the wording in the paper
            ) %>% 
  mutate(bin = row_number())

# plot(x = 1:10, y = car_augment_bins_graph$actual_mean,type = "b")
# points(x = 1:10, y = car_augment_bins_graph$model_2_pred_mean, col = "red")

car_augment_bins_graph %>% ggplot()+
  geom_line(aes(x = bin,y=model_2_pred_mean,col = "red"))+
  geom_line(aes(x = bin,y=actual_mean))

message(paste0("lift: ",max(car_augment_bins_graph$model_2_pred_mean) - min(car_augment_bins_graph$model_2_pred_mean)))


```






```{r}
#slightly modifying cell above, but in real life would functionalize this

set.seed(13472)
car_augment_bins = car_augment %>% 
  mutate(random = runif(nrow(car_holdout))) %>% 
  arrange(model_3_pred,random) %>% 
  mutate(exposure_cumsum = cumsum(exposure)) %>% 
  arrange(model_3_pred) #not needed but to check that ntile worked


  
car_augment_bins = car_augment_bins %>% 
  mutate(bin_model_3_pred = cut(exposure_cumsum,breaks = c(0,1:9*sum(car_augment_bins$exposure)/10,sum(car_augment_bins$exposure)*1.1)))
  
#check bins worked
car_augment_bins %>% 
  group_by(bin_model_3_pred) %>% 
  summarize(total_exposure = sum(exposure),
            model_3_pred_min = min(model_3_pred),
            model_3_pred_max = max(model_3_pred),
            rows = n()) #matches line 53 tapply() exactly

car_augment_bins_graph = car_augment_bins %>% 
  group_by(bin_model_3_pred) %>% 
  summarize(model_3_pred_mean = mean(model_3_pred) / mean(car_augment_bins$model_3_pred), #replaces tapply(dt.holdout$mod.A,dt.holdout$bin.A, mean) / mean(dt.holdout$mod.A)
            actual_mean = mean(claim_cost) / mean(car_augment_bins$model_3_pred) 
            ) %>% 
  mutate(bin = row_number())

car_augment_bins_graph
# plot(x = 1:10, y = car_augment_bins_graph$actual_mean,type = "b")
# points(x = 1:10, y = car_augment_bins_graph$model_3_pred_mean, col = "red")

car_augment_bins_graph %>% ggplot()+
  geom_line(aes(x = bin,y=model_3_pred_mean,col = "red"))+
  geom_line(aes(x = bin,y=actual_mean))

message(paste0("lift: ",max(car_augment_bins_graph$model_3_pred_mean) - min(car_augment_bins_graph$model_3_pred_mean)))


```

double lift chart
```{r}
set.seed(13472)
car_augment_bins = car_augment %>% 
  mutate(model_ratio = model_3_pred/model_2_pred) %>% 
  arrange(model_ratio) %>% 
  mutate(exposure_cumsum = cumsum(exposure)) %>% 
  arrange(model_ratio) #not needed but to check that ntile worked


  
car_augment_bins = car_augment_bins %>% 
  mutate(bin_range = cut(exposure_cumsum,breaks = c(0,1:9*sum(car_augment_bins$exposure)/10,sum(car_augment_bins$exposure)*1.1)))
  
#check bins worked
car_augment_bins %>% 
  group_by(bin_range) %>% 
  summarize(total_exposure = sum(exposure),
            model_3_pred_min = min(model_3_pred),
            model_3_pred_max = max(model_3_pred),
            rows = n()) #matches line 53 tapply() exactly

car_augment_bins_graph = car_augment_bins %>% 
  group_by(bin_range) %>% 
  summarize(model_2_pred_mean = mean(model_2_pred) / mean(car_augment_bins$model_2_pred),
    model_3_pred_mean = mean(model_3_pred) / mean(car_augment_bins$model_3_pred), #replaces tapply(dt.holdout$mod.A,dt.holdout$bin.A, mean) / mean(dt.holdout$mod.A)
            actual_mean = mean(claim_cost) / mean(car_augment_bins$model_3_pred) 
            ) %>% 
  mutate(bin = row_number())

car_augment_bins_graph
# plot(x = 1:10, y = car_augment_bins_graph$actual_mean,type = "b")
# points(x = 1:10, y = car_augment_bins_graph$model_3_pred_mean, col = "red")

car_augment_bins_graph %>% ggplot()+
  geom_line(aes(x = bin,y=model_2_pred_mean,col = "blue"))+
  geom_line(aes(x = bin,y=model_3_pred_mean,col = "red"))+
  geom_line(aes(x = bin,y=actual_mean))
```
ROC
```{r}
pacman::p_load(foreign,rms)

data = suppressWarnings(read.spss("data/t821.sav",to.data.frame = T)) #http://clinicalpredictionmodels.org/doku.php?id=rcode_and_data:start
data = data %>% 
  mutate(actual = NEC)
data
```

```{r}
train = data %>% 
  filter(STUDY == "development") 

full_model = lrm(actual ~ TER + PREAFP + PREHCG + SQPOST + REDUC10,
                 data = train,
                 x = T,
                 y = T) #what is this? lrm() not on syllabus

data_augment = data %>% 
  mutate(pred = predict(full_model, newdata = data, type = "fitted.ind"))

```


```{r}
#training roc
thresholds = seq(.005,.93,length = 50)

data_augment_slim = data_augment %>% 
  filter(STUDY == "development") %>% #training dataset
  select(actual,pred)

roc_data = NULL

for (i in 1:length(thresholds)){
  # i = 25 #uncomment for testing
  temp1 = data_augment_slim %>% 
    mutate(pred_cat = if_else(pred > thresholds[i],1,0))
  
  FPR = nrow(temp1 %>% filter(actual ==0 & pred_cat == 1))/nrow(temp1 %>% filter(actual ==0))
  TPR = nrow(temp1 %>% filter(actual ==1 & pred_cat == 1))/nrow(temp1 %>% filter(actual ==1))
  
  temp2 = data.frame("FPR" = FPR,"TPR" = TPR,"threshold" =  thresholds[i])
  roc_data = bind_rows(roc_data,temp2)
}
roc_data
plot(roc_data$FPR,roc_data$TPR)


#approximate AUC using mid-point as height of the rectangles

```

```{r}
#test roc
thresholds = seq(.005,.93,length = 50)

data_augment_slim = data_augment %>% 
  filter(STUDY != "development") %>% #training dataset
  select(actual,pred)

roc_data = NULL

for (i in 1:length(thresholds)){
  # i = 25 #uncomment for testing
  temp1 = data_augment_slim %>% 
    mutate(pred_cat = if_else(pred > thresholds[i],1,0))
  
  FPR = nrow(temp1 %>% filter(actual ==0 & pred_cat == 1))/nrow(temp1 %>% filter(actual ==0))
  TPR = nrow(temp1 %>% filter(actual ==1 & pred_cat == 1))/nrow(temp1 %>% filter(actual ==1))
  
  temp2 = data.frame("FPR" = FPR,"TPR" = TPR,"threshold" =  thresholds[i])
  roc_data = bind_rows(roc_data,temp2)
}
roc_data
plot(roc_data$FPR,roc_data$TPR)
```

AUC
```{r}
#re-creating paper code more intuitively. see auc.xlsx and auc visul.png
auc_data = roc_data %>% 
  arrange(desc(threshold)) %>% 
  mutate(rect_base = FPR - lag(FPR, n=1)) %>% 
  mutate(rect_height = (TPR + lag(TPR,n=1))/2,
        rect_area = rect_base * rect_height) %>%  #averaging heights of two nearest points. see auc visual.png
  filter(row_number() != 1) 
  
# sum(auc_data$rect_base) #should be close to 1


paste0("AUC: ",round(sum(auc_data$rect_area),3))
#paper calcs .814

#GET THIS TO MATCH THE PAPER

```











```{r}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(ISLR,boot,MASS,class)
source("load_packages.R") #load these last so overwrite functions other packages (like dplyr::select)

```

```{r}
stock_market = ISLR::Smarket
stock_market #could re-create lags with dplyr::lag() but missing first 4 rows of data for lag5 in on first row of data

```

```{r}
pairs(stock_market)

```

```{r}
cor(stock_market %>% select(-Direction))

```

```{r}
# volume going up over time is only correlation
# stock_market %>% 
#   mutate(row_num = row_number()) %>% 
#   ggplot(aes(x = row_num,y = Volume))+
#   geom_point()

stock_market2 = stock_market %>% 
  mutate(row_num = row_number())

plot(stock_market2$row_num,stock_market2$Volume,xlab= "Time",ylab = "Volume")
title("Title")

```

```{r}
model_glm = glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume,
                data = stock_market,
                family = binomial)
summary(model_glm)
```

```{r}
coef(model_glm) #summary(glm_model)$coef[,4] also works
# tidy(model_glm) #in broom package, not on syllabus
```

```{r}
contrasts(stock_market$Direction)

# stock_market %>% count(Direction) #diff as shows counts but not numeric used for each level
```

```{r}
train_augment = stock_market %>% 
  mutate(Direction_pred = predict(model_glm,type = "response")) %>%  # no newdata so will predict on training set. "response" to get results back not in logit terms
  mutate(Direction_pred_label = if_else(Direction_pred>.5,"Up","Down"))

table(train_augment$Direction_pred_label,train_augment$Direction)

message(paste0("training error rate: ",1-mean(train_augment$Direction_pred_label == train_augment$Direction)))
```

```{r}
train = stock_market %>% 
  filter(Year < 2005)

test = stock_market %>% 
  filter(Year >= 2005)

model_glm = glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume,
                data = train,
                family = binomial)
summary(model_glm)
test_augment = test %>% 
  mutate(Direction_pred = predict(model_glm,newdata = test, type = "response")) %>%  # no newdata so will predict on training set. "response" to get results back not in logit terms
  mutate(Direction_pred_label = if_else(Direction_pred>.5,"Up","Down"))

table(test_augment$Direction_pred_label,test_augment$Direction)

message(paste0("test error rate: ",1-mean(test_augment$Direction_pred_label == test_augment$Direction)))
#book builds model on just lag1 and lag2 with 58% accuracy, but you get 56% accuracy predicting up for every day. 
```

```{r}
#predict for one obs
model_glm_simple = glm(Direction ~ Lag1 + Lag2,
                data = train,
                family = binomial)

predict(model_glm_simple,newdata = data.frame(Lag1 = c(1.2,1.5), Lag2 = c(1.1,-0.8)),type = "response")

```

LDA (Linear Discriminant Analysis)
```{r}
# pacman::p_load(MASS) # done at top before dplyr since causes issue with dplyr::select()

model_lda = lda(Direction ~ Lag1 + Lag2, data = train)
model_lda
plot(model_lda) #from equation 4.19. Combination of xvars. if large will predict market up, if small predict market Down. bars from each row of the training data. can get from predict()$x

test_augment = test_augment %>% 
  mutate(Direction_pred_LDA = predict(model_lda,newdata = test)$posterior[,1]) %>%
  mutate(Direction_pred_label_LDA = predict(model_lda,newdata = test)$class)
test_augment #notice LDA posterior is prediction DOWN, unlike glm predicting UP

actual = test_augment$Direction
pred = test_augment$Direction_pred_label_LDA
table(actual,pred) #for some reason feeding the vectors in directly drops labels. Book also switch from actual on x axis in book to actual on y axis in code for lab.
# test_augment %>% count(Direction,Direction_pred_label_LDA) #kind of works but on right format. could spread()

message(paste0("test error rate: ",1-mean(test_augment$Direction_pred_label_LDA == test_augment$Direction)))
#book builds model on just lag1 and lag2 with 58% accuracy, but you get 56% accuracy predicting up for every
```

QDA (Quadratic Discriminant Analysis)
```{r}
model_qda = qda(Direction ~ Lag1 + Lag2, data = train)
model_qda


test_augment = test_augment %>% 
  mutate(Direction_pred_qda = predict(model_qda,newdata = test)$posterior[,1]) %>%
  mutate(Direction_pred_label_qda = predict(model_qda,newdata = test)$class)
test_augment #notice qda posterior is prediction DOWN, unlike glm predicting UP

table(test_augment$Direction_pred_label_qda,test_augment$Direction)

message(paste0("test error rate: ",1-mean(test_augment$Direction_pred_label_qda == test_augment$Direction)))

```

KNN (K-Nearest Neighbors)
```{r}
pacman::p_load(class)

#forms predictions in single command
xvars = c("Lag1","Lag2")


set.seed(1)
model_knn = knn(train = train %>% select(xvars) %>% as.matrix,
                test = test %>% select(xvars) %>% as.matrix,
                cl = train %>% select(Direction) %>% as.matrix,
                k = 3)
actual = test$Direction
table(actual,model_knn)

message(paste0("test error rate: ",1-mean(model_knn == test$Direction)))

```
QDA fit data above the best with lowest test error rate



KNN on Caravan dataset 
```{r}
caravan = ISLR::Caravan
caravan
caravan %>% count(Purchase)
```

```{r}
caravan_scaled = scale(caravan %>% select(-Purchase)) #standardizes and converts to matrix

#split into train/test. I think this should be done before standardizing to avoid leakage

test = 1:1000
train_x = caravan_scaled[-test,]
train_y = caravan$Purchase[-test] #not on scaled data

test_x  = caravan_scaled[test,]
test_y = caravan$Purchase[test] #not on scaled data

set.seed(1)
model_knn = knn(train = train_x,
                test = test_x,
                cl = train_y,
                k = 1)


#KNN has more error than just predicting No:
message(paste0("test error rate: ",1-mean(model_knn == test_y)))
message(paste0("error rate if always predict No: ",mean(test_y != 'No')))

#but don't care about error rate, trying to find pocket with higher hit rates for sales people to focus on. The predictinos of yes has 11.7% hit rate so salespeople can focus there:
table(model_knn,test_y)
9/(68+9)

#k=5 produces best result, but logistic regression still outperforms this
```

```{r}
#http://liacs.leidenuniv.nl/~puttenpwhvander/library/cc2000/data.html  from ?ISLR::Caravan
#caravan data has factor data like:
caravan %>% count(MOSHOOFD)
#this is scaled same as numeric fields above. 

```

















